---
title: "Breast Cancer Prediction"
author: "Andrea Becsek"
date: "2 January 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ggplot2)
library(magrittr)
library(dplyr)
library(ggcorrplot)
library(devtools)
```

Import data
```{r}
data <- read.csv("../data/data.csv")
dim(data)
print(colnames(data))
```
Check for NAs
```{r}
data %>% 
  summarise_all(funs(sum(is.na(.))))
```
Remove *id* and *X*
```{r}
data %<>%  
  dplyr::select(-c(id, X))
```

Correlation plot
```{r}
corr <- data[,-1] %>% 
          cor() %>% 
           round(1)
ggcorrplot(corr, hc.order = TRUE,colors = c("#6D9EC1", "white", "#E46726"),ggtheme = ggplot2::theme_minimal)
```

## Split data into training and test set
```{r}
# use 70% of the data for training and 30% for testing
n <- nrow(data)
train_size <- floor(0.8*n)

# sample indeces for split
train_ind <- sample(seq(n),size = train_size, replace = FALSE)
train <- data[train_ind,]
test <- data[-train_ind,]
```

## Fit lasso
```{r}
# fit lasso
y <- train$diagnosis
X <- train %>% select(-diagnosis) %>% as.matrix()
model_lasso <- glmnet(x=X,y=y, family = "binomial")

# plot of the coefficient paths, excluding the intercept
coefs <- coef(model_lasso)
plot(model_lasso,xvar = "lambda",label=TRUE)
```

Choosing a model using cross-validation
```{r}
cv_lasso <- cv.glmnet(X,y, nfolds = 10, family="binomial",type.measure = "class")

plot(cv_lasso)
```
The selected lambdas are 
```{r}
# lambda that gives the minimum cross-validation error
cv_lasso$lambda.min
# lambda that gives the most regularized model with a cross-validation error within one standard error of the minimum.
cv_lasso$lambda.1se
```

We are going to use *lambda.min* to fit the model.
```{r}
# coefficients
coefs <- coef(cv_lasso,s="lambda.min")
# number of non-zero coefficients
sum(coefs!=0)
```
Make predictions
```{r}
y_test <- test$diagnosis
X_test <- test %>% select(-diagnosis) %>% as.matrix()
predictions <- predict(cv_lasso,newx=X_test,s="lambda.min",type="class")
```

Confusion matrix
```{r}
confusion_matrix <- as.data.frame(table(predictions,y_test))

ggplot(confusion_matrix,aes(y=predictions,x=y_test))+
  geom_tile(aes(fill=Freq))+
  geom_text(aes(label=sprintf("%1.0f", Freq)),color="white",fontface="bold")+
  labs(y="Predicted class",x="True class")+
  theme_minimal()
```

Logistic regression
```{r}
install_github("MauroCE/LogisticRegression")
# add column of 1s
X <- unname(cbind(1,X))
# change factor levels to B=0 and M=1
levels(y) <- c(0,1)
y <- as.matrix(as.integer(y))
model_logistic <- LogisticRegression::logistic_regression(X,y,cost="MAP",method = "newton_method")
```

